{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook is an interim solution for creating tasks before we can do so via a nice GUI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get us into the correct directory to import our fb_auth class\n",
    "# %cd ../lwll_api\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import uuid\n",
    "from typing import Union\n",
    "sys.path.insert(0, os.path.abspath('../lwll_api'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "load_dotenv(dotenv_path=\"../lwll_api/.envs_dev\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# By doing this import, it instantiates a class which reads our appropriate firebase account creds so that\n",
    "# we can import firebase_admin directly after and be authenticated to the database of interest\n",
    "from lwll_api.classes.fb_auth import fb_store\n",
    "from lwll_api.classes.s3_cls import s3_operator\n",
    "from lwll_utils import add_budget_labels_to_task, SeedLabelGenerator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define the Dev, Staging, and Eval Tasks\n",
    "This is a manual process where the base and adaptation datasets are chosen and a whitelist is defined."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lookup tasks if need be\n",
    "task_lookup = fb_store.collection('prod_Task').document('ad348ff9-f6c2-4b21-9bbc-34de6e1ffe10')\n",
    "docs = task_lookup.get()\n",
    "docs.to_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get a new uuid if needed for new tasks\n",
    "uuid.uuid4()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Note*: In the dev and staging tasks, xview has too many seeds to save them to firebase. As a work-around, we just don't include seed labels for xview. We have told performers not to request seed labels for this task. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dev_tasks = [\n",
    "    {\n",
    "        \"task_id\": \"problem_test_video_classification\",\n",
    "        \"problem_type\": \"video_classification\",\n",
    "        \"base_dataset\": \"hmdb\",\n",
    "        \"base_evaluation_metrics\": [\"accuracy\", \"top_5_accuracy\", \"roc_auc\", \"cross_entropy_logloss\", \n",
    "                                          \"brier_score\", \"weighted_accuracy\"],\n",
    "        \"adaptation_dataset\": \"hmdb\",\n",
    "        \"adaptation_evaluation_metrics\": [\"accuracy\", \"top_5_accuracy\", \"roc_auc\", \"cross_entropy_logloss\", \n",
    "                                          \"brier_score\", \"weighted_accuracy\"],\n",
    "        \"whitelist\": [\"imagenet_1k\", \"Kinetics400\", \"Kinetics600\", \"Kinetics700\", \"UCF101\", \"ActivityNet\", \n",
    "                      \"Moments-in-Time\", \"Sports1M\", \"YouTube8M\", \"HACS\", \"HVU\", \"AVA\", \n",
    "                  \"AVA-kinetics\", \"charades\"],\n",
    "        \"optional_sub_tasks\": []\n",
    "    }\n",
    "    ,\n",
    "    {\n",
    "        \"task_id\": '9c103cc4-e2e1-4070-9877-c3b64a6f327f',\n",
    "        \"problem_type\": \"video_classification\",\n",
    "        \"base_dataset\": \"hmdb\",\n",
    "        \"adaptation_dataset\": \"ucf101\",\n",
    "        \"base_evaluation_metrics\": [\"accuracy\", \"top_5_accuracy\", \"roc_auc\", \"cross_entropy_logloss\", \n",
    "                                          \"brier_score\", \"weighted_accuracy\"],\n",
    "        \"adaptation_evaluation_metrics\": [\"accuracy\", \"top_5_accuracy\", \"roc_auc\", \"cross_entropy_logloss\", \n",
    "                                          \"brier_score\", \"weighted_accuracy\"],\n",
    "        \"whitelist\": [\"imagenet_1k\", \"Kinetics400\", \"Kinetics600\", \"Kinetics700\", \"UCF101\", \"ActivityNet\", \n",
    "                      \"Moments-in-Time\", \"Sports1M\", \"YouTube8M\", \"HACS\", \"HVU\", \"AVA\", \n",
    "                  \"AVA-kinetics\", \"charades\"],\n",
    "        \"optional_sub_tasks\": []\n",
    "    },\n",
    "    {\"task_id\": '295ef5ef-1a11-4bc9-8048-0240e9ccd7a1',\n",
    "        \"problem_type\": \"video_classification\",\n",
    "        \"base_dataset\": \"ucf101\",\n",
    "        \"adaptation_dataset\": \"hmdb\",\n",
    "        \"base_evaluation_metrics\": [\"accuracy\", \"top_5_accuracy\", \"roc_auc\", \"cross_entropy_logloss\", \n",
    "                                          \"brier_score\", \"weighted_accuracy\"],\n",
    "        \"adaptation_evaluation_metrics\": [\"accuracy\", \"top_5_accuracy\", \"roc_auc\", \"cross_entropy_logloss\", \n",
    "                                          \"brier_score\", \"weighted_accuracy\"],\n",
    "        \"whitelist\": [\"imagenet_1k\", \"Kinetics400\", \"Kinetics600\", \"Kinetics700\", \"UCF101\", \"ActivityNet\", \n",
    "                      \"Moments-in-Time\", \"Sports1M\", \"YouTube8M\", \"HACS\", \"HVU\", \"AVA\", \n",
    "                  \"AVA-kinetics\", \"charades\"]\n",
    "    },\n",
    "    {\n",
    "        \"task_id\": \"problem_test_image_classification\",\n",
    "        \"problem_type\": \"image_classification\",\n",
    "\t\t\"base_dataset\": \"mnist\",\n",
    "\t\t\"base_evaluation_metrics\": [\"accuracy\", \"top_5_accuracy\", \"roc_auc\", \"cross_entropy_logloss\", \n",
    "                                          \"brier_score\", \"weighted_accuracy\"],\n",
    "\t\t\"adaptation_dataset\": \"mnist\",\n",
    "\t\t\"adaptation_evaluation_metrics\": [\"accuracy\", \"top_5_accuracy\", \"roc_auc\", \"cross_entropy_logloss\", \n",
    "                                          \"brier_score\", \"weighted_accuracy\"],\n",
    "        \"whitelist\": [\"imagenet_1k\", \"coco2014\", \"voc2009\", \"imagenet_bbox\",\n",
    "                     \"domain_net-quickdraw\", \"domain_net-painting\", \"domain_net-infograph\",\n",
    "                     \"domain_net-clipart\", \"domain_net-sketch\", \"cifar100\", \"domain_net-all\",\n",
    "                     \"face_detection\", \"domain_net-real\", \"pool_car_detection\", \"google_open_image\"],\n",
    "        \"optional_sub_tasks\": []\n",
    "    },\n",
    "    {\n",
    "        \"task_id\": \"problem_test_obj_detection\",\n",
    "        \"problem_type\": \"object_detection\",\n",
    "\t\t\"base_dataset\": \"face_detection\",\n",
    "\t\t\"base_evaluation_metrics\": [\"mAP\"],\n",
    "\t\t\"adaptation_dataset\": \"face_detection\",\n",
    "\t\t\"adaptation_evaluation_metrics\": [\"mAP\"],\n",
    "        \"whitelist\": [\"imagenet_1k\", \"coco2014\", \"voc2009\", \"imagenet_bbox\",\n",
    "                     \"domain_net-quickdraw\", \"domain_net-painting\", \"domain_net-infograph\",\n",
    "                     \"domain_net-clipart\", \"domain_net-sketch\", \"cifar100\", \"mnist\", \n",
    "                     \"domain_net-real\", \"pool_car_detection\", \"google_open_image\", \"domain_net-all\"],\n",
    "        \"optional_sub_tasks\": []\n",
    "    }\n",
    "    ,\n",
    "    {\n",
    "        \"task_id\": '6d5e1f85-5d8f-4cc9-8184-299db03713f4',\n",
    "        \"problem_type\": \"image_classification\",\n",
    "\t\t\"base_dataset\": \"cifar100\",\n",
    "\t\t\"base_evaluation_metrics\": [\"accuracy\", \"top_5_accuracy\", \"roc_auc\", \"cross_entropy_logloss\", \n",
    "                                          \"brier_score\", \"weighted_accuracy\"],\n",
    "\t\t\"adaptation_dataset\": \"mnist\",\n",
    "\t\t\"adaptation_evaluation_metrics\": [\"accuracy\", \"top_5_accuracy\", \"roc_auc\", \"cross_entropy_logloss\", \n",
    "                                          \"brier_score\", \"weighted_accuracy\"],\n",
    "        \"whitelist\": [\"imagenet_1k\", \"coco2014\", \"voc2009\", \"imagenet_bbox\",\n",
    "                     \"domain_net-quickdraw\", \"domain_net-painting\", \"domain_net-infograph\",\n",
    "                     \"domain_net-clipart\", \"domain_net-sketch\", \"domain_net-all\",\n",
    "                     \"face_detection\", \"domain_net-real\", \"pool_car_detection\", \"google_open_image\"],\n",
    "        \"optional_sub_tasks\": [\"base_zsl\"]\n",
    "    },\n",
    "    {\n",
    "        \"task_id\": 'bbfadb2c-c7c3-4596-b548-3dd01a6d1d2c',\n",
    "        \"problem_type\": \"image_classification\",\n",
    "\t\t\"base_dataset\": \"domain_net-clipart\",\n",
    "\t\t\"base_evaluation_metrics\": [\"accuracy\", \"top_5_accuracy\", \"roc_auc\", \"cross_entropy_logloss\", \n",
    "                                          \"brier_score\", \"weighted_accuracy\"],\n",
    "\t\t\"adaptation_dataset\": \"domain_net-sketch\",\n",
    "\t\t\"adaptation_evaluation_metrics\": [\"accuracy\", \"top_5_accuracy\", \"roc_auc\", \"cross_entropy_logloss\", \n",
    "                                          \"brier_score\", \"weighted_accuracy\"],\n",
    "        \"whitelist\": [\"imagenet_1k\", \"coco2014\", \"voc2009\", \"imagenet_bbox\",\n",
    "                     \"domain_net-quickdraw\", \"domain_net-painting\", \"domain_net-infograph\",\n",
    "                     \"cifar100\", \"mnist\",\n",
    "                     \"face_detection\", \"domain_net-real\", \"pool_car_detection\", \"google_open_image\"],\n",
    "        \"optional_sub_tasks\": [\"base_zsl\", \"adaptation_zsl\"]\n",
    "    },\n",
    "    {\n",
    "        \"task_id\": 'b01a6738-0b85-46c2-9318-16c3e2ef0f6d',\n",
    "        \"problem_type\": \"image_classification\",\n",
    "\t\t\"base_dataset\": \"domain_net-real\",\n",
    "\t\t\"base_evaluation_metrics\": [\"accuracy\", \"top_5_accuracy\", \"roc_auc\", \"cross_entropy_logloss\", \n",
    "                                          \"brier_score\", \"weighted_accuracy\"],\n",
    "\t\t\"adaptation_dataset\": \"cifar100\",\n",
    "\t\t\"adaptation_evaluation_metrics\": [\"accuracy\", \"top_5_accuracy\", \"roc_auc\", \"cross_entropy_logloss\", \n",
    "                                          \"brier_score\", \"weighted_accuracy\"],\n",
    "        \"whitelist\": [\"imagenet_1k\", \"coco2014\", \"voc2009\", \"imagenet_bbox\",\n",
    "                     \"domain_net-quickdraw\", \"domain_net-painting\", \"domain_net-infograph\",\n",
    "                     \"domain_net-clipart\", \"domain_net-sketch\", \"mnist\",\n",
    "                     \"face_detection\", \"pool_car_detection\", \"google_open_image\"],\n",
    "        \"optional_sub_tasks\": [\"base_zsl\", \"adaptation_zsl\"]\n",
    "    },\n",
    "    {\n",
    "        \"task_id\": '9c391ced-19ed-489a-9be0-ecf11fc4dcab',\n",
    "        \"problem_type\": \"image_classification\",\n",
    "        \"base_dataset\": \"mars_surface_imgs\",\n",
    "        \"adaptation_dataset\": \"msl_curiosity_imgs\",\n",
    "        \"base_evaluation_metrics\": [\"accuracy\", \"top_5_accuracy\", \"roc_auc\", \"cross_entropy_logloss\", \n",
    "                                          \"brier_score\", \"weighted_accuracy\"],\n",
    "        \"adaptation_evaluation_metrics\": [\"accuracy\", \"top_5_accuracy\", \"roc_auc\", \"cross_entropy_logloss\", \n",
    "                                          \"brier_score\", \"weighted_accuracy\"],\n",
    "        \"whitelist\": [\n",
    "            \"imagenet_1k\", \"coco2014\", \"voc2009\", \"imagenet_bbox\", \"cifar100\",\n",
    "             \"domain_net-quickdraw\", \"domain_net-painting\", \"domain_net-infograph\",\n",
    "             \"domain_net-clipart\", \"domain_net-sketch\", \"domain_net-real\", \"mnist\", \n",
    "             \"face_detection\", \"pool_car_detection\", \"google_open_image\"\n",
    "        ],\n",
    "        \"optional_sub_tasks\": []\n",
    "    },\n",
    "    {\n",
    "        \"task_id\": 'ce491694-a660-471c-917b-8f9772b6df37',\n",
    "        \"problem_type\": \"image_classification\",\n",
    "        \"base_dataset\": \"quick_draw_dataset\",\n",
    "        \"adaptation_dataset\": \"imagenet_sketch\",\n",
    "        \"base_evaluation_metrics\": [\"accuracy\", \"top_5_accuracy\", \"roc_auc\", \"cross_entropy_logloss\", \n",
    "                                          \"brier_score\", \"weighted_accuracy\"],\n",
    "        \"adaptation_evaluation_metrics\": [\"accuracy\", \"top_5_accuracy\", \"roc_auc\", \"cross_entropy_logloss\", \n",
    "                                          \"brier_score\", \"weighted_accuracy\"],\n",
    "        \"whitelist\": [\n",
    "            \"imagenet_1k\", \"coco2014\", \"voc2009\", \"imagenet_bbox\", \"cifar100\",\n",
    "             \"domain_net-quickdraw\", \"domain_net-painting\", \"domain_net-infograph\",\n",
    "             \"domain_net-clipart\", \"domain_net-sketch\", \"domain_net-real\", \"mnist\", \n",
    "             \"face_detection\", \"pool_car_detection\", \"google_open_image\"\n",
    "        ],\n",
    "        \"optional_sub_tasks\": []\n",
    "    }, \n",
    "    {\n",
    "        \"task_id\": '5683ee24-bf06-455a-bd25-0942fbcd3b0a',\n",
    "        \"problem_type\": \"image_classification\",\n",
    "        \"base_dataset\": \"iNaturalist\",\n",
    "        \"adaptation_dataset\": \"feathersv1\",\n",
    "        \"base_evaluation_metrics\": [\"accuracy\", \"top_5_accuracy\", \"roc_auc\", \"cross_entropy_logloss\", \n",
    "                                          \"brier_score\", \"weighted_accuracy\"],\n",
    "        \"adaptation_evaluation_metrics\": [\"accuracy\", \"top_5_accuracy\", \"roc_auc\", \"cross_entropy_logloss\", \n",
    "                                          \"brier_score\", \"weighted_accuracy\"],\n",
    "        \"whitelist\": [\n",
    "            \"imagenet_1k\", \"coco2014\", \"voc2009\", \"imagenet_bbox\", \"cifar100\",\n",
    "             \"domain_net-quickdraw\", \"domain_net-painting\", \"domain_net-infograph\",\n",
    "             \"domain_net-clipart\", \"domain_net-sketch\", \"domain_net-real\", \"mnist\", \n",
    "             \"face_detection\", \"pool_car_detection\", \"google_open_image\"\n",
    "        ],\n",
    "        \"optional_sub_tasks\": []\n",
    "    }, \n",
    "    {\n",
    "        \"task_id\": '2a7bb8ea-7c1f-45be-9685-c8afb2a08f23',\n",
    "        \"problem_type\": \"image_classification\",\n",
    "        \"base_dataset\": \"FEIFace\",\n",
    "        \"adaptation_dataset\": \"SheffieldFace\",\n",
    "        \"base_evaluation_metrics\": [\"accuracy\", \"top_5_accuracy\", \"roc_auc\", \"cross_entropy_logloss\", \n",
    "                                          \"brier_score\", \"weighted_accuracy\"],\n",
    "        \"adaptation_evaluation_metrics\": [\"accuracy\", \"top_5_accuracy\", \"roc_auc\", \"cross_entropy_logloss\", \n",
    "                                          \"brier_score\", \"weighted_accuracy\"],\n",
    "        \"whitelist\": [\n",
    "            \"imagenet_1k\", \"coco2014\", \"voc2009\", \"imagenet_bbox\", \"cifar100\",\n",
    "             \"domain_net-quickdraw\", \"domain_net-painting\", \"domain_net-infograph\",\n",
    "             \"domain_net-clipart\", \"domain_net-sketch\", \"domain_net-real\", \"mnist\", \n",
    "             \"face_detection\", \"pool_car_detection\", \"google_open_image\", \"imagenet_22k\"\n",
    "        ],\n",
    "        \"optional_sub_tasks\": []\n",
    "    }, \n",
    "    {\n",
    "        \"task_id\": 'd204349c-01f4-4ae4-844f-811185bf5f33',\n",
    "        \"problem_type\": \"image_classification\",\n",
    "        \"base_dataset\": \"chestXray\",\n",
    "        \"adaptation_dataset\": \"covid_chestXray\",\n",
    "        \"base_evaluation_metrics\": [\"accuracy\", \"top_5_accuracy\", \"roc_auc\", \"cross_entropy_logloss\", \n",
    "                                          \"brier_score\", \"weighted_accuracy\"],\n",
    "        \"adaptation_evaluation_metrics\": [\"accuracy\", \"top_5_accuracy\", \"roc_auc\", \"cross_entropy_logloss\", \n",
    "                                          \"brier_score\", \"weighted_accuracy\"],\n",
    "        \"whitelist\": [\n",
    "            \"imagenet_1k\", \"coco2014\", \"voc2009\", \"imagenet_bbox\", \"cifar100\",\n",
    "             \"domain_net-quickdraw\", \"domain_net-painting\", \"domain_net-infograph\",\n",
    "             \"domain_net-clipart\", \"domain_net-sketch\", \"domain_net-real\", \"mnist\", \n",
    "             \"face_detection\", \"pool_car_detection\", \"google_open_image\", \"imagenet_22k\"\n",
    "        ],\n",
    "        \"optional_sub_tasks\": []\n",
    "    }, \n",
    "    {\n",
    "        \"task_id\": '3b6361a9-bf44-44b9-931f-edb7a5fccd3d',\n",
    "        \"problem_type\": \"image_classification\",\n",
    "        \"base_dataset\": \"AID\",\n",
    "        \"adaptation_dataset\": \"UCMerced_LandUse\",\n",
    "        \"base_evaluation_metrics\": [\"accuracy\", \"top_5_accuracy\", \"roc_auc\", \"cross_entropy_logloss\", \n",
    "                                          \"brier_score\", \"weighted_accuracy\"],\n",
    "        \"adaptation_evaluation_metrics\": [\"accuracy\", \"top_5_accuracy\", \"roc_auc\", \"cross_entropy_logloss\", \n",
    "                                          \"brier_score\", \"weighted_accuracy\"],\n",
    "        \"whitelist\": [\n",
    "            \"imagenet_1k\", \"coco2014\", \"voc2009\", \"imagenet_bbox\", \"cifar100\",\n",
    "             \"domain_net-quickdraw\", \"domain_net-painting\", \"domain_net-infograph\",\n",
    "             \"domain_net-clipart\", \"domain_net-sketch\", \"domain_net-real\", \"mnist\", \n",
    "             \"face_detection\", \"pool_car_detection\", \"google_open_image\", \"imagenet_22k\"\n",
    "        ],\n",
    "        \"optional_sub_tasks\": []\n",
    "    }, \n",
    "            ############################################\n",
    "    {\n",
    "        \"task_id\": \"4d924004-347e-4043-8dd2-f4f8b0f52efd\",\n",
    "        \"problem_type\": \"object_detection\",\n",
    "\t\t\"base_dataset\": \"coco2014_mini\",\n",
    "\t\t\"base_evaluation_metrics\": [\"mAP\"],\n",
    "\t\t\"adaptation_dataset\": \"voc2009\",\n",
    "\t\t\"adaptation_evaluation_metrics\": [\"mAP\"],\n",
    "        \"whitelist\": [\"imagenet_1k\", \"imagenet_bbox\",\n",
    "                     \"domain_net-quickdraw\", \"domain_net-painting\", \"domain_net-infograph\",\n",
    "                     \"domain_net-clipart\", \"domain_net-sketch\", \"cifar100\", \"mnist\", \"domain_net-all\",\n",
    "                     \"face_detection\", \"domain_net-real\", \"pool_car_detection\", \"google_open_image\"],\n",
    "        \"optional_sub_tasks\": []\n",
    "    },\n",
    "    {\n",
    "        \"task_id\": \"d48f8a99-ba12-4df8-a74a-d06413b0f1ba\",\n",
    "        \"problem_type\": \"object_detection\",\n",
    "\t\t\"base_dataset\": \"voc2009\",\n",
    "\t\t\"base_evaluation_metrics\": [\"mAP\"],\n",
    "\t\t\"adaptation_dataset\": \"pool_car_detection\",\n",
    "\t\t\"adaptation_evaluation_metrics\": [\"mAP\"],\n",
    "        \"whitelist\": [\"imagenet_1k\", \"coco2014\", \"imagenet_bbox\",\n",
    "                     \"domain_net-quickdraw\", \"domain_net-painting\", \"domain_net-infograph\",\n",
    "                     \"domain_net-clipart\", \"domain_net-sketch\", \"cifar100\", \"mnist\", \"domain_net-all\",\n",
    "                     \"face_detection\", \"domain_net-real\", \"google_open_image\"],\n",
    "        \"optional_sub_tasks\": []\n",
    "    }\n",
    "    ,\n",
    "    {\n",
    "        \"task_id\": \"7c103ece-fd8e-483b-bede-b55e5ea57fe9\",\n",
    "        \"problem_type\": \"object_detection\",\n",
    "\t\t\"base_dataset\": \"voc2009\",\n",
    "\t\t\"base_evaluation_metrics\": [\"mAP\"],\n",
    "\t\t\"adaptation_dataset\": \"face_detection\",\n",
    "\t\t\"adaptation_evaluation_metrics\": [\"mAP\"],\n",
    "         \"whitelist\": [\"imagenet_1k\", \"coco2014\", \"imagenet_bbox\",\n",
    "                     \"domain_net-quickdraw\", \"domain_net-painting\", \"domain_net-infograph\",\n",
    "                     \"domain_net-clipart\", \"domain_net-sketch\", \"cifar100\", \"mnist\", \"domain_net-all\",\n",
    "                     \"domain_net-real\", \"pool_car_detection\", \"google_open_image\"],\n",
    "        \"optional_sub_tasks\": []\n",
    "    }\n",
    "    ,\n",
    "    {\n",
    "        \"task_id\": \"923cbe9c-1e4f-4a05-a156-dc972ef5edf5\",\n",
    "        \"problem_type\": \"object_detection\",\n",
    "\t\t\"base_dataset\": \"pool_car_detection\",\n",
    "\t\t\"base_evaluation_metrics\": [\"mAP\"],\n",
    "\t\t\"adaptation_dataset\": \"xview\",\n",
    "\t\t\"adaptation_evaluation_metrics\": [\"mAP\"],\n",
    "         \"whitelist\": [\"imagenet_1k\", \"coco2014\", \"imagenet_bbox\", \"voc2009\",\n",
    "                     \"domain_net-quickdraw\", \"domain_net-painting\", \"domain_net-infograph\",\n",
    "                     \"domain_net-clipart\", \"domain_net-sketch\", \"cifar100\", \"mnist\", \"domain_net-all\",\n",
    "                     \"domain_net-real\", \"google_open_image\"]\n",
    "    }\n",
    "    ,\n",
    "    {\n",
    "        \"task_id\": 'dc75cc32-5db1-4767-b41f-b3dfa6b086a9',\n",
    "        \"problem_type\": \"object_detection\",\n",
    "        \"base_dataset\": \"deep_fashion\",\n",
    "        \"adaptation_dataset\": \"deep_fashion_2\",\n",
    "        \"base_evaluation_metrics\": [\"mAP\"],\n",
    "        \"adaptation_evaluation_metrics\": [\"mAP\"],\n",
    "        \"whitelist\": [\"imagenet_1k\", \"coco2014\", \"imagenet_bbox\", \"voc2009\", \"pool_car_detection\", \"xview\",\n",
    "                     \"domain_net-quickdraw\", \"domain_net-painting\", \"domain_net-infograph\",\n",
    "                     \"domain_net-clipart\", \"domain_net-sketch\", \"cifar100\", \"mnist\", \"domain_net-all\",\n",
    "                     \"domain_net-real\", \"google_open_image\"],\n",
    "        \"optional_sub_tasks\": []\n",
    "    },\n",
    "    {\n",
    "        \"task_id\": 'a1182934-69d2-4a46-bcbb-feab912cce2c',\n",
    "        \"problem_type\": \"object_detection\", \n",
    "        \"base_dataset\": \"vis_drone\",\n",
    "        \"adaptation_dataset\": \"stanford_campus_dataset\",\n",
    "        \"base_evaluation_metrics\": [\"mAP\"],\n",
    "        \"adaptation_evaluation_metrics\": [\"mAP\"],\n",
    "        \"whitelist\": [\"imagenet_1k\", \"coco2014\", \"imagenet_bbox\", \"voc2009\", \"pool_car_detection\", \"xview\",\n",
    "                     \"domain_net-quickdraw\", \"domain_net-painting\", \"domain_net-infograph\",\n",
    "                     \"domain_net-clipart\", \"domain_net-sketch\", \"cifar100\", \"mnist\", \"domain_net-all\",\n",
    "                     \"domain_net-real\", \"google_open_image\", \"deep_fashion\", \"deep_fashion_2\"],\n",
    "        \"optional_sub_tasks\": []\n",
    "    }\n",
    "    ,\n",
    "    {\n",
    "        \"task_id\": '7589909f-ca68-4289-8624-25c62c49f0c6',\n",
    "        \"problem_type\": \"object_detection\",\n",
    "        \"base_dataset\": \"widerperson\",\n",
    "        \"adaptation_dataset\": \"nightowls\",\n",
    "        \"base_evaluation_metrics\": [\"mAP\"],\n",
    "        \"adaptation_evaluation_metrics\": [\"mAP\"],\n",
    "        \"whitelist\": [\"imagenet_1k\", \"coco2014\", \"imagenet_bbox\", \"voc2009\", \"pool_car_detection\", \"xview\",\n",
    "             \"domain_net-quickdraw\", \"domain_net-painting\", \"domain_net-infograph\",\n",
    "             \"domain_net-clipart\", \"domain_net-sketch\", \"cifar100\", \"mnist\", \"domain_net-all\",\n",
    "             \"domain_net-real\", \"google_open_image\", \"deep_fashion\", \"deep_fashion_2\", \"vis_drone\", \"stanford_campus_dataset\"],\n",
    "        \"optional_sub_tasks\": []\n",
    "    },\n",
    "    {\n",
    "    \"task_id\": '7e360ff2-291f-4bbc-b2c5-8a484f04e035',\n",
    "    \"problem_type\": \"image_classification\",\n",
    "    \"base_dataset\": \"domain_net-painting\",\n",
    "    \"base_evaluation_metrics\": [\"accuracy\", \"top_5_accuracy\", \"roc_auc\", \"cross_entropy_logloss\", \"brier_score\", \"weighted_accuracy\"],\n",
    "    \"adaptation_dataset\": \"domain_net-real\",\n",
    "    \"adaptation_evaluation_metrics\": [\"accuracy\", \"top_5_accuracy\", \"roc_auc\", \"cross_entropy_logloss\", \"brier_score\", \"weighted_accuracy\"],\n",
    "    \"whitelist\": [\"imagenet_1k\", \"coco2014\", \"voc2009\", \"imagenet_bbox\",\n",
    "                 \"domain_net-quickdraw\", \"domain_net-infograph\",\n",
    "                 \"domain_net-clipart\", \"domain_net-sketch\", \"cifar100\",\n",
    "                 \"face_detection\", \"pool_car_detection\", \"google_open_image\", \n",
    "                  \"mars_surface_imgs\", \"msl_curiosity_imgs\", \"deep_fashion\", \"deep_fashion_2\", \"xview\", \n",
    "                  \"stanford_campus_dataset\", \"vis_drone\"],\n",
    "    \"optional_sub_tasks\": []\n",
    "    },\n",
    "    {\n",
    "        \"task_id\": '10c7919a-a8e3-440d-9bf9-959d4f1f880c',\n",
    "        \"problem_type\": \"object_detection\", \n",
    "        \"base_dataset\": \"stanford_campus_dataset\",\n",
    "        \"adaptation_dataset\": \"pool_car_detection\",\n",
    "        \"base_evaluation_metrics\": [\"mAP\"],\n",
    "        \"adaptation_evaluation_metrics\": [\"mAP\"],\n",
    "        \"whitelist\": [\"imagenet_1k\", \"coco2014\", \"voc2009\", \"imagenet_bbox\",\n",
    "                     \"domain_net-quickdraw\", \"domain_net-painting\", \"domain_net-infograph\",\n",
    "                     \"domain_net-clipart\", \"domain_net-sketch\", \"cifar100\", \"domain_net-all\",\n",
    "                     \"face_detection\", \"domain_net-real\", \"google_open_image\",\n",
    "                      \"mars_surface_imgs\", \"msl_curiosity_imgs\", \"deep_fashion\", \"deep_fashion_2\", \n",
    "                      \"xview\"],\n",
    "        \"optional_sub_tasks\": []\n",
    "    }\n",
    "    ,\n",
    "    {\n",
    "        \"task_id\": \"problem_test_machine_translation\",\n",
    "        \"problem_type\": \"machine_translation\",\n",
    "        \"base_dataset\": \"wikimatrix-fas\",\n",
    "        \"adaptation_dataset\": \"wikimatrix-fas\",\n",
    "        \"base_evaluation_metrics\": [\"bleu\"],\n",
    "        \"adaptation_evaluation_metrics\": [\"bleu\"],\n",
    "        \"whitelist\": []\n",
    "    }\n",
    "    ,\n",
    "    {\n",
    "        \"task_id\": '06023f86-a66b-4b2c-8b8b-951f5edd0f22',\n",
    "        \"problem_type\": \"machine_translation\",\n",
    "\t\t\"base_dataset\": \"global_voices\",\n",
    "\t\t\"base_evaluation_metrics\": [\"bleu\"],\n",
    "\t\t\"adaptation_dataset\": \"ted_talks\",\n",
    "\t\t\"adaptation_evaluation_metrics\": [\"bleu\"],\n",
    "       \"whitelist\": []\n",
    "    }\n",
    "    ,\n",
    "    {\n",
    "        \"task_id\": '3159d8ef-dfef-48fc-9325-829258be5f28',\n",
    "        \"problem_type\": \"machine_translation\",\n",
    "        \"base_dataset\": \"cc_aligned_sinhala\",\n",
    "        \"base_evaluation_metrics\": [\"bleu\"],\n",
    "        \"adaptation_dataset\": \"wikimatrix-sin\",\n",
    "        \"adaptation_evaluation_metrics\": [\"bleu\"],\n",
    "       \"whitelist\": []\n",
    "    }\n",
    "    ,\n",
    "    {\n",
    "        \"task_id\": '9877df6a-746f-400e-ac7a-71ca87f50057',\n",
    "        \"problem_type\": \"machine_translation\",\n",
    "        \"base_dataset\": \"cc_aligned_polish\",\n",
    "        \"base_evaluation_metrics\": [\"bleu\"],\n",
    "        \"adaptation_dataset\": \"wikimatrix-pol\",\n",
    "        \"adaptation_evaluation_metrics\": [\"bleu\"],\n",
    "       \"whitelist\": []\n",
    "    }\n",
    "    ,\n",
    "    {\n",
    "        \"task_id\": '36ff86c2-9403-4fbc-af78-ba2fb54c1734',\n",
    "        \"problem_type\": \"machine_translation\",\n",
    "        \"base_dataset\": \"cc_aligned_persian\",\n",
    "        \"base_evaluation_metrics\": [\"bleu\"],\n",
    "        \"adaptation_dataset\": \"wikimatrix-fas\",\n",
    "        \"adaptation_evaluation_metrics\": [\"bleu\"],\n",
    "       \"whitelist\": []\n",
    "    }\n",
    "    \n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "staging_tasks = [\n",
    "    {\n",
    "        \"task_id\": \"problem_test_video_classification\",\n",
    "        \"problem_type\": \"video_classification\",\n",
    "        \"base_dataset\": \"hmdb\",\n",
    "        \"base_evaluation_metrics\": [\"accuracy\", \"top_5_accuracy\", \"roc_auc\", \"cross_entropy_logloss\", \n",
    "                                          \"brier_score\", \"weighted_accuracy\"],\n",
    "        \"adaptation_dataset\": \"hmdb\",\n",
    "        \"adaptation_evaluation_metrics\": [\"accuracy\", \"top_5_accuracy\", \"roc_auc\", \"cross_entropy_logloss\", \n",
    "                                          \"brier_score\", \"weighted_accuracy\"],\n",
    "        \"whitelist\": [\"imagenet_1k\", \"Kinetics400\", \"Kinetics600\", \"Kinetics700\", \"UCF101\", \"ActivityNet\", \n",
    "                      \"Moments-in-Time\", \"Sports1M\", \"YouTube8M\", \"HACS\", \"HVU\", \"AVA\", \n",
    "                  \"AVA-kinetics\", \"charades\"],\n",
    "        \"optional_sub_tasks\": []\n",
    "    }\n",
    "    ,\n",
    "    {\n",
    "        \"task_id\": '9c103cc4-e2e1-4070-9877-c3b64a6f327f',\n",
    "        \"problem_type\": \"video_classification\",\n",
    "        \"base_dataset\": \"hmdb\",\n",
    "        \"adaptation_dataset\": \"ucf101\",\n",
    "        \"base_evaluation_metrics\": [\"accuracy\", \"top_5_accuracy\", \"roc_auc\", \"cross_entropy_logloss\", \n",
    "                                          \"brier_score\", \"weighted_accuracy\"],\n",
    "        \"adaptation_evaluation_metrics\": [\"accuracy\", \"top_5_accuracy\", \"roc_auc\", \"cross_entropy_logloss\", \n",
    "                                          \"brier_score\", \"weighted_accuracy\"],\n",
    "        \"whitelist\": [\"imagenet_1k\", \"Kinetics400\", \"Kinetics600\", \"Kinetics700\", \"UCF101\", \"ActivityNet\", \n",
    "                      \"Moments-in-Time\", \"Sports1M\", \"YouTube8M\", \"HACS\", \"HVU\", \"AVA\", \n",
    "                  \"AVA-kinetics\", \"charades\"],\n",
    "        \"optional_sub_tasks\": []\n",
    "    },\n",
    "    {\"task_id\": '295ef5ef-1a11-4bc9-8048-0240e9ccd7a1',\n",
    "        \"problem_type\": \"video_classification\",\n",
    "        \"base_dataset\": \"ucf101\",\n",
    "        \"adaptation_dataset\": \"hmdb\",\n",
    "        \"base_evaluation_metrics\": [\"accuracy\", \"top_5_accuracy\", \"roc_auc\", \"cross_entropy_logloss\", \n",
    "                                          \"brier_score\", \"weighted_accuracy\"],\n",
    "        \"adaptation_evaluation_metrics\": [\"accuracy\", \"top_5_accuracy\", \"roc_auc\", \"cross_entropy_logloss\", \n",
    "                                          \"brier_score\", \"weighted_accuracy\"],\n",
    "        \"whitelist\": [\"imagenet_1k\", \"Kinetics400\", \"Kinetics600\", \"Kinetics700\", \"UCF101\", \"ActivityNet\", \n",
    "                      \"Moments-in-Time\", \"Sports1M\", \"YouTube8M\", \"HACS\", \"HVU\", \"AVA\", \n",
    "                  \"AVA-kinetics\", \"charades\"]\n",
    "    },\n",
    "    {\n",
    "        \"task_id\": \"problem_test_image_classification\",\n",
    "        \"problem_type\": \"image_classification\",\n",
    "\t\t\"base_dataset\": \"mnist\",\n",
    "\t\t\"base_evaluation_metrics\": [\"accuracy\", \"top_5_accuracy\", \"roc_auc\", \"cross_entropy_logloss\", \n",
    "                                          \"brier_score\", \"weighted_accuracy\"],\n",
    "\t\t\"adaptation_dataset\": \"mnist\",\n",
    "\t\t\"adaptation_evaluation_metrics\": [\"accuracy\", \"top_5_accuracy\", \"roc_auc\", \"cross_entropy_logloss\", \n",
    "                                          \"brier_score\", \"weighted_accuracy\"],\n",
    "        \"whitelist\": [\"imagenet_1k\", \"coco2014\", \"voc2009\", \"imagenet_bbox\",\n",
    "                     \"domain_net-quickdraw\", \"domain_net-painting\", \"domain_net-infograph\",\n",
    "                     \"domain_net-clipart\", \"domain_net-sketch\", \"cifar100\", \"domain_net-all\",\n",
    "                     \"face_detection\", \"domain_net-real\", \"pool_car_detection\", \"google_open_image\"],\n",
    "        \"optional_sub_tasks\": []\n",
    "    },\n",
    "    {\n",
    "        \"task_id\": \"problem_test_obj_detection\",\n",
    "        \"problem_type\": \"object_detection\",\n",
    "\t\t\"base_dataset\": \"face_detection\",\n",
    "\t\t\"base_evaluation_metrics\": [\"mAP\"],\n",
    "\t\t\"adaptation_dataset\": \"face_detection\",\n",
    "\t\t\"adaptation_evaluation_metrics\": [\"mAP\"],\n",
    "        \"whitelist\": [\"imagenet_1k\", \"coco2014\", \"voc2009\", \"imagenet_bbox\",\n",
    "                     \"domain_net-quickdraw\", \"domain_net-painting\", \"domain_net-infograph\",\n",
    "                     \"domain_net-clipart\", \"domain_net-sketch\", \"cifar100\", \"mnist\", \n",
    "                     \"domain_net-real\", \"pool_car_detection\", \"google_open_image\", \"domain_net-all\"],\n",
    "        \"optional_sub_tasks\": []\n",
    "    }\n",
    "    ,\n",
    "    {\n",
    "        \"task_id\": '6d5e1f85-5d8f-4cc9-8184-299db03713f4',\n",
    "        \"problem_type\": \"image_classification\",\n",
    "\t\t\"base_dataset\": \"cifar100\",\n",
    "\t\t\"base_evaluation_metrics\": [\"accuracy\", \"top_5_accuracy\", \"roc_auc\", \"cross_entropy_logloss\", \n",
    "                                          \"brier_score\", \"weighted_accuracy\"],\n",
    "\t\t\"adaptation_dataset\": \"mnist\",\n",
    "\t\t\"adaptation_evaluation_metrics\": [\"accuracy\", \"top_5_accuracy\", \"roc_auc\", \"cross_entropy_logloss\", \n",
    "                                          \"brier_score\", \"weighted_accuracy\"],\n",
    "        \"whitelist\": [\"imagenet_1k\", \"coco2014\", \"voc2009\", \"imagenet_bbox\",\n",
    "                     \"domain_net-quickdraw\", \"domain_net-painting\", \"domain_net-infograph\",\n",
    "                     \"domain_net-clipart\", \"domain_net-sketch\", \"domain_net-all\",\n",
    "                     \"face_detection\", \"domain_net-real\", \"pool_car_detection\", \"google_open_image\"],\n",
    "        \"optional_sub_tasks\": [\"base_zsl\"]\n",
    "    },\n",
    "    {\n",
    "        \"task_id\": 'bbfadb2c-c7c3-4596-b548-3dd01a6d1d2c',\n",
    "        \"problem_type\": \"image_classification\",\n",
    "\t\t\"base_dataset\": \"domain_net-clipart\",\n",
    "\t\t\"base_evaluation_metrics\": [\"accuracy\", \"top_5_accuracy\", \"roc_auc\", \"cross_entropy_logloss\", \n",
    "                                          \"brier_score\", \"weighted_accuracy\"],\n",
    "\t\t\"adaptation_dataset\": \"domain_net-sketch\",\n",
    "\t\t\"adaptation_evaluation_metrics\": [\"accuracy\", \"top_5_accuracy\", \"roc_auc\", \"cross_entropy_logloss\", \n",
    "                                          \"brier_score\", \"weighted_accuracy\"],\n",
    "        \"whitelist\": [\"imagenet_1k\", \"coco2014\", \"voc2009\", \"imagenet_bbox\",\n",
    "                     \"domain_net-quickdraw\", \"domain_net-painting\", \"domain_net-infograph\",\n",
    "                     \"cifar100\", \"mnist\",\n",
    "                     \"face_detection\", \"domain_net-real\", \"pool_car_detection\", \"google_open_image\"],\n",
    "        \"optional_sub_tasks\": [\"base_zsl\", \"adaptation_zsl\"]\n",
    "    },\n",
    "    {\n",
    "        \"task_id\": 'b01a6738-0b85-46c2-9318-16c3e2ef0f6d',\n",
    "        \"problem_type\": \"image_classification\",\n",
    "\t\t\"base_dataset\": \"domain_net-real\",\n",
    "\t\t\"base_evaluation_metrics\": [\"accuracy\", \"top_5_accuracy\", \"roc_auc\", \"cross_entropy_logloss\", \n",
    "                                          \"brier_score\", \"weighted_accuracy\"],\n",
    "\t\t\"adaptation_dataset\": \"cifar100\",\n",
    "\t\t\"adaptation_evaluation_metrics\": [\"accuracy\", \"top_5_accuracy\", \"roc_auc\", \"cross_entropy_logloss\", \n",
    "                                          \"brier_score\", \"weighted_accuracy\"],\n",
    "        \"whitelist\": [\"imagenet_1k\", \"coco2014\", \"voc2009\", \"imagenet_bbox\",\n",
    "                     \"domain_net-quickdraw\", \"domain_net-painting\", \"domain_net-infograph\",\n",
    "                     \"domain_net-clipart\", \"domain_net-sketch\", \"mnist\",\n",
    "                     \"face_detection\", \"pool_car_detection\", \"google_open_image\"],\n",
    "        \"optional_sub_tasks\": [\"base_zsl\", \"adaptation_zsl\"]\n",
    "    },\n",
    "    {\n",
    "        \"task_id\": '9c391ced-19ed-489a-9be0-ecf11fc4dcab',\n",
    "        \"problem_type\": \"image_classification\",\n",
    "        \"base_dataset\": \"mars_surface_imgs\",\n",
    "        \"adaptation_dataset\": \"msl_curiosity_imgs\",\n",
    "        \"base_evaluation_metrics\": [\"accuracy\", \"top_5_accuracy\", \"roc_auc\", \"cross_entropy_logloss\", \n",
    "                                          \"brier_score\", \"weighted_accuracy\"],\n",
    "        \"adaptation_evaluation_metrics\": [\"accuracy\", \"top_5_accuracy\", \"roc_auc\", \"cross_entropy_logloss\", \n",
    "                                          \"brier_score\", \"weighted_accuracy\"],\n",
    "        \"whitelist\": [\n",
    "            \"imagenet_1k\", \"coco2014\", \"voc2009\", \"imagenet_bbox\", \"cifar100\",\n",
    "             \"domain_net-quickdraw\", \"domain_net-painting\", \"domain_net-infograph\",\n",
    "             \"domain_net-clipart\", \"domain_net-sketch\", \"domain_net-real\", \"mnist\", \n",
    "             \"face_detection\", \"pool_car_detection\", \"google_open_image\"\n",
    "        ],\n",
    "        \"optional_sub_tasks\": []\n",
    "    },\n",
    "    {\n",
    "        \"task_id\": 'ce491694-a660-471c-917b-8f9772b6df37',\n",
    "        \"problem_type\": \"image_classification\",\n",
    "        \"base_dataset\": \"quick_draw_dataset\",\n",
    "        \"adaptation_dataset\": \"imagenet_sketch\",\n",
    "        \"base_evaluation_metrics\": [\"accuracy\", \"top_5_accuracy\", \"roc_auc\", \"cross_entropy_logloss\", \n",
    "                                          \"brier_score\", \"weighted_accuracy\"],\n",
    "        \"adaptation_evaluation_metrics\": [\"accuracy\", \"top_5_accuracy\", \"roc_auc\", \"cross_entropy_logloss\", \n",
    "                                          \"brier_score\", \"weighted_accuracy\"],\n",
    "        \"whitelist\": [\n",
    "            \"imagenet_1k\", \"coco2014\", \"voc2009\", \"imagenet_bbox\", \"cifar100\",\n",
    "             \"domain_net-quickdraw\", \"domain_net-painting\", \"domain_net-infograph\",\n",
    "             \"domain_net-clipart\", \"domain_net-sketch\", \"domain_net-real\", \"mnist\", \n",
    "             \"face_detection\", \"pool_car_detection\", \"google_open_image\"\n",
    "        ],\n",
    "        \"optional_sub_tasks\": []\n",
    "    }, \n",
    "    {\n",
    "        \"task_id\": '5683ee24-bf06-455a-bd25-0942fbcd3b0a',\n",
    "        \"problem_type\": \"image_classification\",\n",
    "        \"base_dataset\": \"iNaturalist\",\n",
    "        \"adaptation_dataset\": \"feathersv1\",\n",
    "        \"base_evaluation_metrics\": [\"accuracy\", \"top_5_accuracy\", \"roc_auc\", \"cross_entropy_logloss\", \n",
    "                                          \"brier_score\", \"weighted_accuracy\"],\n",
    "        \"adaptation_evaluation_metrics\": [\"accuracy\", \"top_5_accuracy\", \"roc_auc\", \"cross_entropy_logloss\", \n",
    "                                          \"brier_score\", \"weighted_accuracy\"],\n",
    "        \"whitelist\": [\n",
    "            \"imagenet_1k\", \"coco2014\", \"voc2009\", \"imagenet_bbox\", \"cifar100\",\n",
    "             \"domain_net-quickdraw\", \"domain_net-painting\", \"domain_net-infograph\",\n",
    "             \"domain_net-clipart\", \"domain_net-sketch\", \"domain_net-real\", \"mnist\", \n",
    "             \"face_detection\", \"pool_car_detection\", \"google_open_image\"\n",
    "        ],\n",
    "        \"optional_sub_tasks\": []\n",
    "    }, \n",
    "            #############################################\n",
    "    {\n",
    "        \"task_id\": \"4d924004-347e-4043-8dd2-f4f8b0f52efd\",\n",
    "        \"problem_type\": \"object_detection\",\n",
    "\t\t\"base_dataset\": \"coco2014_mini\",\n",
    "\t\t\"base_evaluation_metrics\": [\"mAP\"],\n",
    "\t\t\"adaptation_dataset\": \"voc2009\",\n",
    "\t\t\"adaptation_evaluation_metrics\": [\"mAP\"],\n",
    "        \"whitelist\": [\"imagenet_1k\", \"imagenet_bbox\",\n",
    "                     \"domain_net-quickdraw\", \"domain_net-painting\", \"domain_net-infograph\",\n",
    "                     \"domain_net-clipart\", \"domain_net-sketch\", \"cifar100\", \"mnist\", \"domain_net-all\",\n",
    "                     \"face_detection\", \"domain_net-real\", \"pool_car_detection\", \"google_open_image\"],\n",
    "        \"optional_sub_tasks\": []\n",
    "    },\n",
    "    {\n",
    "        \"task_id\": \"d48f8a99-ba12-4df8-a74a-d06413b0f1ba\",\n",
    "        \"problem_type\": \"object_detection\",\n",
    "\t\t\"base_dataset\": \"voc2009\",\n",
    "\t\t\"base_evaluation_metrics\": [\"mAP\"],\n",
    "\t\t\"adaptation_dataset\": \"pool_car_detection\",\n",
    "\t\t\"adaptation_evaluation_metrics\": [\"mAP\"],\n",
    "        \"whitelist\": [\"imagenet_1k\", \"coco2014\", \"imagenet_bbox\",\n",
    "                     \"domain_net-quickdraw\", \"domain_net-painting\", \"domain_net-infograph\",\n",
    "                     \"domain_net-clipart\", \"domain_net-sketch\", \"cifar100\", \"mnist\", \"domain_net-all\",\n",
    "                     \"face_detection\", \"domain_net-real\", \"google_open_image\"],\n",
    "        \"optional_sub_tasks\": []\n",
    "    }\n",
    "    ,\n",
    "    {\n",
    "        \"task_id\": \"7c103ece-fd8e-483b-bede-b55e5ea57fe9\",\n",
    "        \"problem_type\": \"object_detection\",\n",
    "\t\t\"base_dataset\": \"voc2009\",\n",
    "\t\t\"base_evaluation_metrics\": [\"mAP\"],\n",
    "\t\t\"adaptation_dataset\": \"face_detection\",\n",
    "\t\t\"adaptation_evaluation_metrics\": [\"mAP\"],\n",
    "         \"whitelist\": [\"imagenet_1k\", \"coco2014\", \"imagenet_bbox\",\n",
    "                     \"domain_net-quickdraw\", \"domain_net-painting\", \"domain_net-infograph\",\n",
    "                     \"domain_net-clipart\", \"domain_net-sketch\", \"cifar100\", \"mnist\", \"domain_net-all\",\n",
    "                     \"domain_net-real\", \"pool_car_detection\", \"google_open_image\"],\n",
    "        \"optional_sub_tasks\": []\n",
    "    }\n",
    "    ,\n",
    "    {\n",
    "        \"task_id\": \"923cbe9c-1e4f-4a05-a156-dc972ef5edf5\",\n",
    "        \"problem_type\": \"object_detection\",\n",
    "\t\t\"base_dataset\": \"pool_car_detection\",\n",
    "\t\t\"base_evaluation_metrics\": [\"mAP\"],\n",
    "\t\t\"adaptation_dataset\": \"xview\",\n",
    "\t\t\"adaptation_evaluation_metrics\": [\"mAP\"],\n",
    "         \"whitelist\": [\"imagenet_1k\", \"coco2014\", \"imagenet_bbox\", \"voc2009\",\n",
    "                     \"domain_net-quickdraw\", \"domain_net-painting\", \"domain_net-infograph\",\n",
    "                     \"domain_net-clipart\", \"domain_net-sketch\", \"cifar100\", \"mnist\", \"domain_net-all\",\n",
    "                     \"domain_net-real\", \"google_open_image\"]\n",
    "    },\n",
    "    {\n",
    "        \"task_id\": 'dc75cc32-5db1-4767-b41f-b3dfa6b086a9',\n",
    "        \"problem_type\": \"object_detection\",\n",
    "        \"base_dataset\": \"deep_fashion\",\n",
    "        \"adaptation_dataset\": \"deep_fashion_2\",\n",
    "        \"base_evaluation_metrics\": [\"mAP\"],\n",
    "        \"adaptation_evaluation_metrics\": [\"mAP\"],\n",
    "        \"whitelist\": [\"imagenet_1k\", \"coco2014\", \"imagenet_bbox\", \"voc2009\", \"pool_car_detection\", \"xview\",\n",
    "                     \"domain_net-quickdraw\", \"domain_net-painting\", \"domain_net-infograph\",\n",
    "                     \"domain_net-clipart\", \"domain_net-sketch\", \"cifar100\", \"mnist\", \"domain_net-all\",\n",
    "                     \"domain_net-real\", \"google_open_image\"],\n",
    "        \"optional_sub_tasks\": []\n",
    "    },\n",
    "    {\n",
    "        \"task_id\": 'a1182934-69d2-4a46-bcbb-feab912cce2c',\n",
    "        \"problem_type\": \"object_detection\", \n",
    "        \"base_dataset\": \"vis_drone\",\n",
    "        \"adaptation_dataset\": \"stanford_campus_dataset\",\n",
    "        \"base_evaluation_metrics\": [\"mAP\"],\n",
    "        \"adaptation_evaluation_metrics\": [\"mAP\"],\n",
    "        \"whitelist\": [\"imagenet_1k\", \"coco2014\", \"imagenet_bbox\", \"voc2009\", \"pool_car_detection\", \"xview\",\n",
    "                     \"domain_net-quickdraw\", \"domain_net-painting\", \"domain_net-infograph\",\n",
    "                     \"domain_net-clipart\", \"domain_net-sketch\", \"cifar100\", \"mnist\", \"domain_net-all\",\n",
    "                     \"domain_net-real\", \"google_open_image\", \"deep_fashion\", \"deep_fashion_2\"],\n",
    "        \"optional_sub_tasks\": []\n",
    "    }\n",
    "    ,\n",
    "    {\n",
    "        \"task_id\": '7589909f-ca68-4289-8624-25c62c49f0c6',\n",
    "        \"problem_type\": \"object_detection\",\n",
    "        \"base_dataset\": \"widerperson\",\n",
    "        \"adaptation_dataset\": \"nightowls\",\n",
    "        \"base_evaluation_metrics\": [\"mAP\"],\n",
    "        \"adaptation_evaluation_metrics\": [\"mAP\"],\n",
    "        \"whitelist\": [\"imagenet_1k\", \"coco2014\", \"imagenet_bbox\", \"voc2009\", \"pool_car_detection\", \"xview\",\n",
    "             \"domain_net-quickdraw\", \"domain_net-painting\", \"domain_net-infograph\",\n",
    "             \"domain_net-clipart\", \"domain_net-sketch\", \"cifar100\", \"mnist\", \"domain_net-all\",\n",
    "             \"domain_net-real\", \"google_open_image\", \"deep_fashion\", \"deep_fashion_2\", \"vis_drone\", \"stanford_campus_dataset\"],\n",
    "        \"optional_sub_tasks\": []\n",
    "    },\n",
    "    {\n",
    "    \"task_id\": '7e360ff2-291f-4bbc-b2c5-8a484f04e035',\n",
    "    \"problem_type\": \"image_classification\",\n",
    "    \"base_dataset\": \"domain_net-painting\",\n",
    "    \"base_evaluation_metrics\": [\"accuracy\", \"top_5_accuracy\", \"roc_auc\", \"cross_entropy_logloss\", \"brier_score\", \"weighted_accuracy\"],\n",
    "    \"adaptation_dataset\": \"domain_net-real\",\n",
    "    \"adaptation_evaluation_metrics\": [\"accuracy\", \"top_5_accuracy\", \"roc_auc\", \"cross_entropy_logloss\", \"brier_score\", \"weighted_accuracy\"],\n",
    "    \"whitelist\": [\"imagenet_1k\", \"coco2014\", \"voc2009\", \"imagenet_bbox\",\n",
    "                 \"domain_net-quickdraw\", \"domain_net-infograph\",\n",
    "                 \"domain_net-clipart\", \"domain_net-sketch\", \"cifar100\", \"domain_net-all\",\n",
    "                 \"face_detection\", \"pool_car_detection\", \"google_open_image\", \n",
    "                  \"mars_surface_imgs\", \"msl_curiosity_imgs\", \"deep_fashion\", \"deep_fashion_2\", \"xview\", \n",
    "                  \"stanford_campus_dataset\", \"vis_drone\"],\n",
    "    \"optional_sub_tasks\": []\n",
    "    },\n",
    "    {\n",
    "        \"task_id\": '10c7919a-a8e3-440d-9bf9-959d4f1f880c',\n",
    "        \"problem_type\": \"object_detection\", \n",
    "        \"base_dataset\": \"stanford_campus_dataset\",\n",
    "        \"adaptation_dataset\": \"pool_car_detection\",\n",
    "        \"base_evaluation_metrics\": [\"mAP\"],\n",
    "        \"adaptation_evaluation_metrics\": [\"mAP\"],\n",
    "        \"whitelist\": [\"imagenet_1k\", \"coco2014\", \"voc2009\", \"imagenet_bbox\",\n",
    "                     \"domain_net-quickdraw\", \"domain_net-painting\", \"domain_net-infograph\",\n",
    "                     \"domain_net-clipart\", \"domain_net-sketch\", \"cifar100\", \"domain_net-all\",\n",
    "                     \"face_detection\", \"domain_net-real\", \"google_open_image\",\n",
    "                      \"mars_surface_imgs\", \"msl_curiosity_imgs\", \"deep_fashion\", \"deep_fashion_2\", \n",
    "                      \"xview\"],\n",
    "        \"optional_sub_tasks\": []\n",
    "    }\n",
    "    ,\n",
    "    {\n",
    "        \"task_id\": \"problem_test_machine_translation\",\n",
    "        \"problem_type\": \"machine_translation\",\n",
    "        \"base_dataset\": \"wikimatrix-fas\",\n",
    "        \"adaptation_dataset\": \"wikimatrix-fas\",\n",
    "        \"base_evaluation_metrics\": [\"bleu\"],\n",
    "        \"adaptation_evaluation_metrics\": [\"bleu\"],\n",
    "        \"whitelist\": []\n",
    "    }\n",
    "    ,\n",
    "    {\n",
    "        \"task_id\": '06023f86-a66b-4b2c-8b8b-951f5edd0f22',\n",
    "        \"problem_type\": \"machine_translation\",\n",
    "\t\t\"base_dataset\": \"global_voices\",\n",
    "\t\t\"base_evaluation_metrics\": [\"bleu\"],\n",
    "\t\t\"adaptation_dataset\": \"ted_talks\",\n",
    "\t\t\"adaptation_evaluation_metrics\": [\"bleu\"],\n",
    "       \"whitelist\": []\n",
    "    }\n",
    "    ,\n",
    "    {\n",
    "        \"task_id\": '3159d8ef-dfef-48fc-9325-829258be5f28',\n",
    "        \"problem_type\": \"machine_translation\",\n",
    "        \"base_dataset\": \"cc_aligned_sinhala\",\n",
    "        \"base_evaluation_metrics\": [\"bleu\"],\n",
    "        \"adaptation_dataset\": \"wikimatrix-sin\",\n",
    "        \"adaptation_evaluation_metrics\": [\"bleu\"],\n",
    "       \"whitelist\": []\n",
    "    }\n",
    "    ,\n",
    "    {\n",
    "        \"task_id\": '9877df6a-746f-400e-ac7a-71ca87f50057',\n",
    "        \"problem_type\": \"machine_translation\",\n",
    "        \"base_dataset\": \"cc_aligned_polish\",\n",
    "        \"base_evaluation_metrics\": [\"bleu\"],\n",
    "        \"adaptation_dataset\": \"wikimatrix-pol\",\n",
    "        \"adaptation_evaluation_metrics\": [\"bleu\"],\n",
    "       \"whitelist\": []\n",
    "    }\n",
    "    ,\n",
    "    {\n",
    "        \"task_id\": '36ff86c2-9403-4fbc-af78-ba2fb54c1734',\n",
    "        \"problem_type\": \"machine_translation\",\n",
    "        \"base_dataset\": \"cc_aligned_persian\",\n",
    "        \"base_evaluation_metrics\": [\"bleu\"],\n",
    "        \"adaptation_dataset\": \"wikimatrix-fas\",\n",
    "        \"adaptation_evaluation_metrics\": [\"bleu\"],\n",
    "       \"whitelist\": []\n",
    "    }\n",
    "    \n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# These tasks are not truly used in the evaluation, they are only used to test changes made to this repo when no\n",
    "# changes have been made to the eval tasks. This is to avoid inadvertent updates to the eval tasks. \n",
    "test_eval_tasks = [\n",
    "       {\n",
    "        \"task_id\": \"problem_test_image_classification\",\n",
    "        \"problem_type\": \"image_classification\",\n",
    "\t\t\"base_dataset\": \"mnist\",\n",
    "\t\t\"base_evaluation_metrics\": [\"accuracy\", \"top_5_accuracy\", \"roc_auc\", \"cross_entropy_logloss\", \"brier_score\", \"weighted_accuracy\"],\n",
    "\t\t\"adaptation_dataset\": \"mnist\",\n",
    "\t\t\"adaptation_evaluation_metrics\": [\"accuracy\", \"top_5_accuracy\", \"roc_auc\", \"cross_entropy_logloss\", \"brier_score\", \"weighted_accuracy\"],\n",
    "        \"whitelist\": [\"imagenet_1k\", \"coco2014\", \"voc2009\", \"imagenet_bbox\", \n",
    "                     \"domain_net-quickdraw\", \"domain_net-painting\", \"domain_net-infograph\",\n",
    "                     \"domain_net-clipart\", \"domain_net-sketch\", \"cifar100\", \"domain_net-all\",\n",
    "                     \"face_detection\", \"domain_net-real\", \"pool_car_detection\", \"google_open_image\",\n",
    "                      \"mars_surface_imgs\", \"msl_curiosity_imgs\", \"deep_fashion\", \"deep_fashion_2\", \n",
    "                      \"xview\", \"stanford_campus_dataset\", \"vis_drone\"]\n",
    "    }\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_tasks = [\n",
    "    {\n",
    "        \"task_id\": \"7260a913-f1fd-4436-88bd-37a49f7d4ef8\",\n",
    "        \"problem_type\": \"image_classification\",\n",
    "\t\t\"base_dataset\": \"hotels_50k-hotels\",\n",
    "\t\t\"base_evaluation_metrics\": [\"accuracy\", \"top_5_accuracy\", \"roc_auc\", \"cross_entropy_logloss\", \"brier_score\", \"weighted_accuracy\"],\n",
    "\t\t\"adaptation_dataset\": \"hotels_50k-trafficcam\",\n",
    "\t\t\"adaptation_evaluation_metrics\": [\"accuracy\", \"top_5_accuracy\", \"roc_auc\", \"cross_entropy_logloss\", \"brier_score\", \"weighted_accuracy\"],\n",
    "        \"whitelist\": [\"imagenet_1k\", \"coco2014\", \"voc2009\", \"imagenet_bbox\", \"mnist\",\n",
    "                     \"domain_net-quickdraw\", \"domain_net-painting\", \"domain_net-infograph\",\n",
    "                     \"domain_net-clipart\", \"domain_net-sketch\", \"cifar100\", \"domain_net-all\",\n",
    "                     \"face_detection\", \"domain_net-real\", \"pool_car_detection\", \"google_open_image\",\n",
    "                      \"mars_surface_imgs\", \"msl_curiosity_imgs\", \"deep_fashion\", \"deep_fashion_2\", \n",
    "                      \"xview\", \"stanford_campus_dataset\", \"vis_drone\"]\n",
    "    },\n",
    "    {\n",
    "        \"task_id\": \"7f11ce22-981f-4952-94e0-e4be24f686eb\",\n",
    "        \"problem_type\": \"image_classification\",\n",
    "\t\t\"base_dataset\": \"places2-base\",\n",
    "\t\t\"base_evaluation_metrics\": [\"accuracy\", \"top_5_accuracy\", \"roc_auc\", \"cross_entropy_logloss\", \"brier_score\", \"weighted_accuracy\"],\n",
    "\t\t\"adaptation_dataset\": \"places2-adpt\",\n",
    "\t\t\"adaptation_evaluation_metrics\": [\"accuracy\", \"top_5_accuracy\", \"roc_auc\", \"cross_entropy_logloss\", \"brier_score\", \"weighted_accuracy\"],\n",
    "        \"whitelist\": [\"imagenet_1k\", \"coco2014\", \"voc2009\", \"imagenet_bbox\", \"mnist\",\n",
    "                     \"domain_net-quickdraw\", \"domain_net-painting\", \"domain_net-infograph\",\n",
    "                     \"domain_net-clipart\", \"domain_net-sketch\", \"cifar100\", \"domain_net-all\",\n",
    "                     \"face_detection\", \"domain_net-real\", \"pool_car_detection\", \"google_open_image\",\n",
    "                      \"mars_surface_imgs\", \"msl_curiosity_imgs\", \"deep_fashion\", \"deep_fashion_2\", \n",
    "                      \"xview\", \"stanford_campus_dataset\", \"vis_drone\"]\n",
    "    },\n",
    "    {\n",
    "        \"task_id\": \"b453dc4e-5b8e-42b5-a748-d0e59113ec69\",\n",
    "        \"problem_type\": \"image_classification\",\n",
    "\t\t\"base_dataset\": \"nwpu_resisc45\",\n",
    "\t\t\"base_evaluation_metrics\": [\"accuracy\", \"top_5_accuracy\", \"roc_auc\", \"cross_entropy_logloss\", \"brier_score\", \"weighted_accuracy\"],\n",
    "\t\t\"adaptation_dataset\": \"pattern_net\",\n",
    "\t\t\"adaptation_evaluation_metrics\": [\"accuracy\", \"top_5_accuracy\", \"roc_auc\", \"cross_entropy_logloss\", \"brier_score\", \"weighted_accuracy\"],\n",
    "        \"whitelist\": [\"imagenet_1k\", \"coco2014\", \"voc2009\", \"imagenet_bbox\", \"mnist\",\n",
    "                     \"domain_net-quickdraw\", \"domain_net-painting\", \"domain_net-infograph\",\n",
    "                     \"domain_net-clipart\", \"domain_net-sketch\", \"cifar100\", \"domain_net-all\",\n",
    "                     \"face_detection\", \"domain_net-real\", \"pool_car_detection\", \"google_open_image\",\n",
    "                      \"mars_surface_imgs\", \"msl_curiosity_imgs\", \"deep_fashion\", \"deep_fashion_2\", \n",
    "                      \"xview\", \"stanford_campus_dataset\", \"vis_drone\"]\n",
    "    },\n",
    "    {\n",
    "        \"task_id\": \"ad348ff9-f6c2-4b21-9bbc-34de6e1ffe10\",\n",
    "        \"problem_type\": \"image_classification\",\n",
    "\t\t\"base_dataset\": \"google_landmarks_v1\",\n",
    "\t\t\"base_evaluation_metrics\": [\"accuracy\", \"top_5_accuracy\", \"roc_auc\", \"cross_entropy_logloss\", \"brier_score\", \"weighted_accuracy\"],\n",
    "\t\t\"adaptation_dataset\": \"google_landmarks_v2\",\n",
    "\t\t\"adaptation_evaluation_metrics\": [\"accuracy\", \"top_5_accuracy\", \"roc_auc\", \"cross_entropy_logloss\", \"brier_score\", \"weighted_accuracy\"],\n",
    "        \"whitelist\": [\"imagenet_1k\", \"coco2014\", \"voc2009\", \"imagenet_bbox\", \"mnist\",\n",
    "                     \"domain_net-quickdraw\", \"domain_net-painting\", \"domain_net-infograph\",\n",
    "                     \"domain_net-clipart\", \"domain_net-sketch\", \"cifar100\", \"domain_net-all\",\n",
    "                     \"face_detection\", \"domain_net-real\", \"pool_car_detection\", \"google_open_image\",\n",
    "                      \"mars_surface_imgs\", \"msl_curiosity_imgs\", \"deep_fashion\", \"deep_fashion_2\", \n",
    "                      \"xview\", \"stanford_campus_dataset\", \"vis_drone\"]\n",
    "    },\n",
    "    {\n",
    "        \"task_id\": \"3a475004-2ca6-48a4-8569-84bd81116af3\",\n",
    "        \"problem_type\": \"object_detection\",\n",
    "\t\t\"base_dataset\": \"bdd_100k-day\",\n",
    "\t\t\"base_evaluation_metrics\": [\"mAP\"],\n",
    "\t\t\"adaptation_dataset\": \"bdd_100k-night\",\n",
    "\t\t\"adaptation_evaluation_metrics\": [\"mAP\"],\n",
    "        \"whitelist\": [\"imagenet_1k\", \"coco2014\", \"voc2009\", \"imagenet_bbox\", \"mnist\",\n",
    "                     \"domain_net-quickdraw\", \"domain_net-painting\", \"domain_net-infograph\",\n",
    "                     \"domain_net-clipart\", \"domain_net-sketch\", \"cifar100\", \"domain_net-all\",\n",
    "                     \"face_detection\", \"domain_net-real\", \"pool_car_detection\", \"google_open_image\",\n",
    "                      \"mars_surface_imgs\", \"msl_curiosity_imgs\", \"deep_fashion\", \"deep_fashion_2\", \n",
    "                      \"xview\"]\n",
    "    },\n",
    "    {\n",
    "        \"task_id\": \"0f0706dc-5dc2-4e7d-a1d1-5cbc42344a0a\",\n",
    "        \"problem_type\": \"object_detection\",\n",
    "\t\t\"base_dataset\": \"bdd_100k-all\",\n",
    "\t\t\"base_evaluation_metrics\": [\"mAP\"],\n",
    "\t\t\"adaptation_dataset\": \"idd\",\n",
    "\t\t\"adaptation_evaluation_metrics\": [\"mAP\"],\n",
    "        \"whitelist\": [\"imagenet_1k\", \"coco2014\", \"voc2009\", \"imagenet_bbox\", \"mnist\",\n",
    "                     \"domain_net-quickdraw\", \"domain_net-painting\", \"domain_net-infograph\",\n",
    "                     \"domain_net-clipart\", \"domain_net-sketch\", \"cifar100\", \"domain_net-all\",\n",
    "                     \"face_detection\", \"domain_net-real\", \"pool_car_detection\", \"google_open_image\",\n",
    "                      \"mars_surface_imgs\", \"msl_curiosity_imgs\", \"deep_fashion\", \"deep_fashion_2\", \n",
    "                      \"xview\"]\n",
    "    },\n",
    "    {\n",
    "        \"task_id\": \"f892c2f4-9184-409c-925a-4ce4f639c5c3\",\n",
    "        \"problem_type\": \"object_detection\",\n",
    "\t\t\"base_dataset\": \"ug2-glider\",\n",
    "\t\t\"base_evaluation_metrics\": [\"mAP\"],\n",
    "\t\t\"adaptation_dataset\": \"ug2-uav\",\n",
    "\t\t\"adaptation_evaluation_metrics\": [\"mAP\"],\n",
    "        \"whitelist\": [\"imagenet_1k\", \"coco2014\", \"voc2009\", \"imagenet_bbox\", \"mnist\",\n",
    "                     \"domain_net-quickdraw\", \"domain_net-painting\", \"domain_net-infograph\",\n",
    "                     \"domain_net-clipart\", \"domain_net-sketch\", \"cifar100\", \"domain_net-all\",\n",
    "                     \"face_detection\", \"domain_net-real\", \"pool_car_detection\", \"google_open_image\",\n",
    "                      \"mars_surface_imgs\", \"msl_curiosity_imgs\", \"deep_fashion\", \"deep_fashion_2\", \n",
    "                      \"xview\"]\n",
    "    },\n",
    "    {\n",
    "        \"task_id\": \"93eb7ebc-a0da-4a7c-a544-ed8bfb3668bf\",\n",
    "        \"problem_type\": \"object_detection\",\n",
    "\t\t\"base_dataset\": \"auair\",\n",
    "\t\t\"base_evaluation_metrics\": [\"mAP\"],\n",
    "\t\t\"adaptation_dataset\": \"wilddash2\",\n",
    "\t\t\"adaptation_evaluation_metrics\": [\"mAP\"],\n",
    "        \"whitelist\": [\"imagenet_1k\", \"coco2014\", \"voc2009\", \"imagenet_bbox\", \"mnist\",\n",
    "                     \"domain_net-quickdraw\", \"domain_net-painting\", \"domain_net-infograph\",\n",
    "                     \"domain_net-clipart\", \"domain_net-sketch\", \"cifar100\", \"domain_net-all\",\n",
    "                     \"face_detection\", \"domain_net-real\", \"pool_car_detection\", \"google_open_image\",\n",
    "                      \"mars_surface_imgs\", \"msl_curiosity_imgs\", \"deep_fashion\", \"deep_fashion_2\", \n",
    "                      \"xview\"]\n",
    "    },\n",
    "    {\n",
    "        \"task_id\": \"bbcdae4e-7a55-4240-8e3c-daa5968a77cd\",\n",
    "        \"problem_type\": \"object_detection\",\n",
    "\t\t\"base_dataset\": \"kal_base\",\n",
    "\t\t\"base_evaluation_metrics\": [\"mAP\"],\n",
    "\t\t\"adaptation_dataset\": \"kal_adpt\",\n",
    "\t\t\"adaptation_evaluation_metrics\": [\"mAP\"],\n",
    "        \"whitelist\": [\"imagenet_1k\", \"coco2014\", \"imagenet_bbox\", \"voc2009\", \"pool_car_detection\", \n",
    "                      \"xview\",\"domain_net-quickdraw\", \"domain_net-painting\", \"domain_net-infograph\",\n",
    "                      \"domain_net-clipart\", \"domain_net-sketch\", \"cifar100\", \"mnist\", \"domain_net-all\",\n",
    "                      \"domain_net-real\", \"google_open_image\", \"deep_fashion\", \"deep_fashion_2\", \"vis_drone\", \n",
    "                      \"stanford_campus_dataset\", \"cowc\", \"dota\", \"fair1m\", \"imagenet_22k\"]\n",
    "    },\n",
    "    {\n",
    "        \"task_id\": \"eab7e083-880e-44ba-a412-afe8065e7394\",\n",
    "        \"problem_type\": \"object_detection\",\n",
    "\t\t\"base_dataset\": \"kal_base\",\n",
    "\t\t\"base_evaluation_metrics\": [\"mAP\"],\n",
    "\t\t\"adaptation_dataset\": \"kal_adpt\",\n",
    "\t\t\"adaptation_evaluation_metrics\": [\"mAP\"],\n",
    "        \"whitelist\": [\"imagenet_1k\", \"coco2014\", \"imagenet_bbox\", \"voc2009\", \"pool_car_detection\", \n",
    "                      \"xview\",\"domain_net-quickdraw\", \"domain_net-painting\", \"domain_net-infograph\",\n",
    "                      \"domain_net-clipart\", \"domain_net-sketch\", \"cifar100\", \"mnist\", \"domain_net-all\",\n",
    "                      \"domain_net-real\", \"google_open_image\", \"deep_fashion\", \"deep_fashion_2\", \"vis_drone\", \n",
    "                      \"stanford_campus_dataset\", \"cowc\", \"dota\", \"fair1m\", \"imagenet_22k\"]\n",
    "    },\n",
    "    {\n",
    "        \"task_id\": 'e145bcd7-8d64-4817-8db1-6307f197449d',\n",
    "        \"problem_type\": \"machine_translation\",\n",
    "\t\t\"base_dataset\": \"gale\",\n",
    "\t\t\"base_evaluation_metrics\": [\"bleu\"],\n",
    "\t\t\"adaptation_dataset\": \"ted_talks\",\n",
    "\t\t\"adaptation_evaluation_metrics\": [\"bleu\"],\n",
    "        \"whitelist\": []\n",
    "    },\n",
    "    {\n",
    "        \"task_id\": '75fb4978-66ce-479e-8ebc-d53ba2f08e57',\n",
    "        \"problem_type\": \"machine_translation\",\n",
    "\t\t\"base_dataset\": \"paracrawl_portuguese\",\n",
    "\t\t\"base_evaluation_metrics\": [\"bleu\"],\n",
    "\t\t\"adaptation_dataset\": \"pubmed_portuguese\",\n",
    "\t\t\"adaptation_evaluation_metrics\": [\"bleu\"],\n",
    "        \"whitelist\": []\n",
    "    },\n",
    "    {\n",
    "        \"task_id\": '7109e533-beb7-4e61-95ef-0cf11cbe3a77',\n",
    "        \"problem_type\": \"machine_translation\",\n",
    "\t\t\"base_dataset\": \"gale_arabic\",\n",
    "\t\t\"base_evaluation_metrics\": [\"bleu\"],\n",
    "\t\t\"adaptation_dataset\": \"bolt_arabic\",\n",
    "\t\t\"adaptation_evaluation_metrics\": [\"bleu\"],\n",
    "        \"whitelist\": []\n",
    "    },\n",
    "    {\n",
    "        \"task_id\": 'a4d0ef87-1970-4b50-a3c1-bc4e98d7caf0',\n",
    "        \"problem_type\": \"machine_translation\",\n",
    "\t\t\"base_dataset\": \"hunglish\",\n",
    "\t\t\"base_evaluation_metrics\": [\"bleu\"],\n",
    "\t\t\"adaptation_dataset\": \"paracrawl_hungarian\",\n",
    "\t\t\"adaptation_evaluation_metrics\": [\"bleu\"],\n",
    "        \"whitelist\": []\n",
    "    },\n",
    "        {\n",
    "        \"task_id\": 'b9a612a8-c0e4-4079-acd7-14a8f3022468',\n",
    "        \"problem_type\": \"video_classification\",\n",
    "        \"base_dataset\": \"ek_base\",\n",
    "        \"adaptation_dataset\": \"ek_adpt\",\n",
    "        \"base_evaluation_metrics\": [\"accuracy\", \"top_5_accuracy\", \"roc_auc\", \"cross_entropy_logloss\", \n",
    "                                          \"brier_score\", \"weighted_accuracy\"],\n",
    "        \"adaptation_evaluation_metrics\": [\"accuracy\", \"top_5_accuracy\", \"roc_auc\", \"cross_entropy_logloss\", \n",
    "                                          \"brier_score\", \"weighted_accuracy\"],\n",
    "        \"whitelist\": [\"imagenet_1k\", \"Kinetics400\", \"Kinetics600\", \"Kinetics700\", \"UCF101\", \"ActivityNet\", \n",
    "                      \"Moments-in-Time\", \"Sports1M\", \"YouTube8M\", \"HACS\", \"HVU\", \"AVA\", \n",
    "                      \"AVA-kinetics\", \"charades\"]\n",
    "    }\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Add the budgets to the tasks\n",
    "Calling `add_budget_labels_to_task` adds the budgets in place. Pass `sample=True` only for dev and staging tasks to create budgets for the sample size as well. Evaluation tasks have no sample data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "add_budget_labels_to_task(dev_tasks, sample=True)\n",
    "dev_tasks[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "add_budget_labels_to_task(staging_tasks, sample=True)\n",
    "staging_tasks[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "add_budget_labels_to_task(test_eval_tasks, sample=True)\n",
    "test_eval_tasks[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "add_budget_labels_to_task(eval_tasks, sample=True)\n",
    "eval_tasks[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create task in firebase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_or_update_task(task, level='dev'):\n",
    "    \"\"\"\n",
    "    Checks if the task exists. If it does, it updates all the fields in\n",
    "    the task. Otherwise, it creates the task\n",
    "    \"\"\"\n",
    "    _id = task['task_id']\n",
    "    doc_ref = fb_store.collection(f'{level}_Task').document(_id)\n",
    "    doc = doc_ref.get()\n",
    "    if doc.exists:\n",
    "        print(f\"Found task: {_id}. Updating contents\")\n",
    "        for field, value in task.items():\n",
    "            doc_ref.update({field: value})\n",
    "    else:\n",
    "        print(f\"Creating new task: {_id}\")\n",
    "        fb_store.collection(f'{level}_Task').document(_id).set(task)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create/Update dev tasks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for task in dev_tasks:\n",
    "    create_or_update_task(task, level='dev')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create/Update staging tasks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for task in staging_tasks:\n",
    "    create_or_update_task(task, level='staging')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create/Update eval tasks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for task in test_eval_tasks:\n",
    "    create_or_update_task(task, level='prod')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for task in eval_tasks:\n",
    "    create_or_update_task(task, level='prod')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create seed labels for each dataset in the tasks\n",
    "First, we loop through the tasks and get a set of all the image_classification, object_detection, and video_classification dataset names. There is no concept of seeds for machine translation. We separate the types out because they are handled differently. We do this first because some tasks use the same dataset, and we don't want to compute seed labels for the same set multiple times. Then we will assign the appropriate seed labels to the task. \n",
    "\n",
    "\n",
    "This is done after we create the task in firebase because some of the seed label sets are quite large and would result in too large of a request, so the base and adaptation labels are added separately using an update. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dataset_names(task_list: list):\n",
    "    \"\"\"\n",
    "    Gets a set of all the dataset names in a task list:\n",
    "    Args:\n",
    "        task_list: list of dicts: dev, staging, or eval task list\n",
    "    \"\"\"\n",
    "    cls_datasets, obj_det_datasets, video_datasets = set(), set(), set()\n",
    "    for task in task_list:\n",
    "        if task['problem_type'] == \"image_classification\":\n",
    "            cls_datasets.add(task['base_dataset'])\n",
    "            cls_datasets.add(task['adaptation_dataset'])\n",
    "        elif task['problem_type'] == \"object_detection\":\n",
    "            obj_det_datasets.add(task['base_dataset'])\n",
    "            obj_det_datasets.add(task['adaptation_dataset'])\n",
    "        elif task['problem_type'] == 'video_classification':\n",
    "            video_datasets.add(task['base_dataset'])\n",
    "            video_datasets.add(task['adaptation_dataset'])\n",
    "    return cls_datasets, obj_det_datasets, video_datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dev_cls_datasets, dev_obj_datasets, dev_vid_datasets = get_dataset_names(dev_tasks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "staging_cls_datasets, staging_obj_datasets, staging_vid_datasets = get_dataset_names(staging_tasks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_eval_cls_datasets, test_eval_obj_datasets, test_eval_vid_datasets = get_dataset_names(test_eval_tasks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_cls_datasets, eval_obj_datasets, eval_vid_datasets = get_dataset_names(eval_tasks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dev_cls_datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dev_obj_datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dev_vid_datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a seed generator object that will connect to S3 to get labels. The same object can be used for every dataset. For the development and staging tasks, we use the sample dataset to create the seeds, so both the sample and full dataset will have the same seeds. For the eval tasks, there are no sample datasets, and we create seeds from the full dataset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed_generator = SeedLabelGenerator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_seeds(cls_datasets, obj_det_datasets, video_datasets, sample, level):\n",
    "    seeds = {}\n",
    "    for dataset_name in cls_datasets:\n",
    "        print(dataset_name)\n",
    "        lbls = seed_generator.get_train_labels(dataset_name=dataset_name, level=level, sample=sample)\n",
    "        num_classes = lbls['class'].nunique()\n",
    "        print(f\"num unique classes in lbls: {num_classes}\")\n",
    "        try:\n",
    "              seeds[dataset_name] = seed_generator.create_seed_lbls(lbls, problem_type='image_classification')\n",
    "        except Exception as e:\n",
    "              print(e)\n",
    "    \n",
    "    for dataset_name in obj_det_datasets:\n",
    "        if dataset_name == \"xview\" or dataset_name == \"pool_car_detection\":\n",
    "            print(f\"Setting {dataset_name} seeds to None.\")\n",
    "            seeds[dataset_name] = {\n",
    "                \"0\": None,\n",
    "                \"1\": None,\n",
    "                \"2\": None,\n",
    "                \"3\": None\n",
    "            }\n",
    "        else:\n",
    "            print(dataset_name)\n",
    "            lbls = seed_generator.get_train_labels(dataset_name=dataset_name, level=level, sample=sample)\n",
    "            num_ids = lbls['id'].nunique()\n",
    "            try:\n",
    "                seeds[dataset_name] = seed_generator.create_seed_lbls(lbls, problem_type='object_detection')\n",
    "\n",
    "            except Exception as e:\n",
    "                print(f\"Error, could not generate seed labels: {e}\")\n",
    "    \n",
    "    for dataset_name in video_datasets:\n",
    "        print(dataset_name)\n",
    "        lbls = seed_generator.get_train_labels(dataset_name=dataset_name, level=level, sample=sample)\n",
    "        try:\n",
    "            seeds[dataset_name] = seed_generator.create_seed_lbls(lbls, problem_type='video_classification')\n",
    "\n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "    return seeds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For dev/staging tasks, use the labels from the sample size feather file so that the full and sample size have \n",
    "# the same sample seeds.\n",
    "print(\"Getting dev sample seeds\")\n",
    "dev_seeds = get_seeds(dev_cls_datasets, dev_obj_datasets, dev_vid_datasets, False, level='dev')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Getting staging seeds\")\n",
    "staging_seeds = get_seeds(staging_cls_datasets, staging_obj_datasets, staging_vid_datasets, False, level='staging')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Getting test_eval seeds\")\n",
    "# The level is set to dev because the test problems are not in the lwll-datasets bucket,\n",
    "# but not lwll-eval-datasets bucket\n",
    "test_eval_seeds = get_seeds(test_eval_cls_datasets, test_eval_obj_datasets, test_eval_vid_datasets, False, level='eval')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(\"Getting eval seeds\")\n",
    "eval_seeds = get_seeds(eval_cls_datasets, eval_obj_datasets, eval_vid_datasets, False, level='eval')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Store the seeds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_seeds(task, all_seeds, level='dev'):\n",
    "    if level not in ['dev', 'staging', 'prod']:\n",
    "        raise Exception(f\"Expected level to be `dev`, `staging`, or `prod`, but got {level}\")\n",
    "    if task['problem_type'] != \"machine_translation\":\n",
    "        _id = task['task_id']\n",
    "        print(_id)\n",
    "        task_ref = fb_store.collection(f'{level}_Task').document(task['task_id'])\n",
    "        try:\n",
    "            for key, seeds in all_seeds[task['base_dataset']].items():\n",
    "                task_ref.update({f\"base_seed_labels.{key}\": seeds})\n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "            dataset = task['base_dataset']\n",
    "            print(f\"failed on {dataset} at checkpoint {key}\") \n",
    "        try:\n",
    "            for key, seeds in all_seeds[task['adaptation_dataset']].items():\n",
    "                task_ref.update({f\"adaptation_seed_labels.{key}\": seeds})\n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "            dataset = task['adaptation_dataset']\n",
    "            print(f\"failed on {dataset} at checkpoint {key}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for task in dev_tasks:\n",
    "    if task['problem_type'] != \"machine_translation\":\n",
    "        _id = task['task_id']\n",
    "        print(f\"getting seeds for task {_id}\")\n",
    "        save_seeds(task, dev_seeds, 'dev')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for task in staging_tasks:\n",
    "    if task['problem_type'] != \"machine_translation\":\n",
    "        _id = task['task_id']\n",
    "        print(f\"saving seeds for task {_id}\")\n",
    "        save_seeds(task, staging_seeds, 'staging')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for task in test_eval_tasks:\n",
    "    if task['problem_type'] != \"machine_translation\":\n",
    "        _id = task['task_id']\n",
    "        print(f\"getting seeds for task {_id}\")\n",
    "        save_seeds(task, test_eval_seeds, 'prod')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for task in eval_tasks:\n",
    "    if task['problem_type'] != \"machine_translation\":\n",
    "        _id = task['task_id']\n",
    "        print(f\"getting seeds for task {_id}\")\n",
    "        save_seeds(task, eval_seeds, 'prod')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Add class overlap \n",
    "For the tasks, we get the % overlap in class names from base -> adaptation and adaptation -> base so that performers can decide if they want to do unsupervised domain adaptation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_class_overlap(task: dict, level: str):\n",
    "    \"\"\"\n",
    "    Retrieves class names for base and adaptation datasets, gets dataset metadata from FB, calculates % overlap.\n",
    "    Args:\n",
    "        task: dict in format\n",
    "        {\n",
    "            \"task_id\": \"prod_test_image_classification\",\n",
    "            \"problem_type\": \"image_classification\",\n",
    "            \"base_dataset\": \"mnist\",\n",
    "            \"base_evaluation_metrics\": [\"accuracy\"],\n",
    "            \"adaptation_dataset\": \"mnist\",\n",
    "            \"adaptation_evaluation_metrics\": [\"accuracy\"],\n",
    "            \"whitelist\": [\"imagenet_1k\", \"coco2014\", \"voc2009\", \"imagenet_bbox\",\n",
    "                         \"domain_net-quickdraw\", \"domain_net-painting\", \"domain_net-infograph\",\n",
    "                         \"domain_net-clipart\", \"domain_net-sketch\", \"cifar100\", \"domain_net-all\",\n",
    "                         \"face_detection\", \"domain_net-real\", \"pool_car_detection\", \"google_open_image\"]\n",
    "        }\n",
    "        level: str, valid values are 'dev', 'staging', 'prod'\n",
    "\n",
    "    \"\"\"\n",
    "    if level not in [\"dev\", \"staging\", \"prod\"]:\n",
    "        print(\"Invalid task type\")\n",
    "        return\n",
    "    if task['problem_type'] == \"machine_translation\":\n",
    "        print(\"Skipping machine translation problem\")\n",
    "        return\n",
    "    \n",
    "    # get base classes\n",
    "    base_meta = fb_store.collection('DatasetMetadata').document(task['base_dataset']).get().to_dict()\n",
    "    base_classes = base_meta['classes']\n",
    "    base_classes = [str(item).lower() for item in base_classes]\n",
    "    \n",
    "    # get adapt classes\n",
    "    adaptation_meta = fb_store.collection('DatasetMetadata').document(task['adaptation_dataset']).get().to_dict()\n",
    "    adaptation_classes = adaptation_meta['classes']\n",
    "    adaptation_classes = [str(item).lower() for item in adaptation_classes]\n",
    "    \n",
    "    # calculate overlap and store\n",
    "    intersection = len(set(base_classes).intersection(set(adaptation_classes)))\n",
    "    base_to_adapt_overlap = intersection / len(base_classes) \n",
    "    if base_to_adapt_overlap == 0:\n",
    "        base_to_adapt_overlap = 0.0001\n",
    "    adapt_to_base_overlap = intersection / len(adaptation_classes)\n",
    "    if adapt_to_base_overlap == 0:\n",
    "        adapt_to_base_overlap = 0.0001\n",
    "    if task[\"problem_type\"] == \"image_classification\":\n",
    "        base = task[\"base_dataset\"]\n",
    "        adapt = task[\"adaptation_dataset\"]\n",
    "    task_ref = fb_store.collection(f'{level}_Task').document(task['task_id'])\n",
    "    task_ref.update({\"uda_base_to_adapt_overlap_ratio\": base_to_adapt_overlap})\n",
    "    task_ref.update({\"uda_adapt_to_base_overlap_ratio\": adapt_to_base_overlap})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for task in dev_tasks:\n",
    "    _id = task['task_id']\n",
    "    print(f\"adding uda overlap to task {_id}\")  \n",
    "    add_class_overlap(task, level=\"dev\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for task in staging_tasks:\n",
    "    _id = task['task_id']\n",
    "    print(f\"adding uda overlap to task {_id}\")  \n",
    "    add_class_overlap(task, level=\"staging\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for task in test_eval_tasks:\n",
    "    _id = task['task_id']\n",
    "    print(f\"adding uda overlap to task {_id}\")  \n",
    "    add_class_overlap(task, level=\"prod\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for task in eval_tasks:\n",
    "    _id = task['task_id']\n",
    "    print(f\"adding uda overlap to task {_id}\")  \n",
    "    add_class_overlap(task, level=\"prod\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Update any field"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_task_field(task_id: str, level: str, field: str, value: Union[list, str]):\n",
    "    \"\"\"\n",
    "    Updates any field of a task\n",
    "    Args:\n",
    "        task_id: str, The unique id of the task\n",
    "        level: str, valid values are 'dev', 'staging', 'prod'\n",
    "        field: str, the key of the field to be updated\n",
    "        value: Union[str, list], the data to update\n",
    "    \"\"\"\n",
    "    if level not in [\"dev\", \"staging\", \"prod\"]:\n",
    "        print(\"Invalid task type\")\n",
    "        return    \n",
    "\n",
    "    # Get the task\n",
    "    task_ref = fb_store.collection(f'{level}_Task').document(task_id)\n",
    "    \n",
    "    # update the task\n",
    "    try:\n",
    "        task_ref.update({field: value})\n",
    "    except KeyError:\n",
    "        task_ref.create({field: value})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for task in staging_tasks:\n",
    "    task_id = task['task_id']\n",
    "    if 'optional_sub_tasks' in task.keys():\n",
    "        print(f\"updating task {task_id}\")\n",
    "        update_task_field(task_id, 'staging', 'optional_sub_tasks', task['optional_sub_tasks'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for task in eval_tasks:\n",
    "    task_id = task['task_id']\n",
    "    update_task_field(task_id, 'prod', 'base_label_budget_sample', task['base_label_budget_sample'])\n",
    "    update_task_field(task_id, 'prod', 'adaptation_label_budget_sample', task['adaptation_label_budget_sample'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for task in eval_tasks:\n",
    "    task_id = task['task_id']\n",
    "    update_task_field(task_id, 'prod', 'base_label_budget_sample', task['base_label_budget_sample'])\n",
    "    update_task_field(task_id, 'prod', 'base_label_budget_full', task['base_label_budget_full'])\n",
    "    update_task_field(task_id, 'prod', 'adaptation_label_budget_sample', task['adaptation_label_budget_sample'])\n",
    "    update_task_field(task_id, 'prod', 'adaptation_label_budget_full', task['adaptation_label_budget_full'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "task_ref = fb_store.collection(f'dev_Task').document('problem_test_image_classification')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc = task_ref.get()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc.to_dict()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Removing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# active key from bool to str\n",
    "# def rename_active_key(coll_ref, batch_size):\n",
    "#     docs = coll_ref.get()\n",
    "#     for doc in docs:\n",
    "#         data = doc.to_dict()\n",
    "#         if data['active'] is True:\n",
    "#             data['active'] = 'In Progress'\n",
    "#         elif data['active'] is False:\n",
    "#             data['active'] = 'Complete'\n",
    "#         coll_ref.document(doc.id).update(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rename_active_key(fb_store.collection('dev_Session'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def remove_data_urls(coll_ref):\n",
    "#     docs = coll_ref.get()\n",
    "#     for doc in docs:\n",
    "#         data = doc.to_dict()\n",
    "#         data['full_data_url'] = None\n",
    "#         data['sample_data_url'] = None\n",
    "#         coll_ref.document(doc.id).update(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove_data_urls(fb_store.collection('DatasetMetadata'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Purge all Sessions WARNING YOU USUALLY DO NOT WANT TO DO THIS. \n",
    "# THIS IS ONLY USEFUL IN EARLY DEVELOPMENT WHILE DATA SCHEMAS ARE CHANGING\n",
    "\n",
    "# def delete_collection(coll_ref, batch_size):\n",
    "#     docs = coll_ref.limit(batch_size).get()\n",
    "#     deleted = 0\n",
    "\n",
    "#     for doc in docs:\n",
    "#         print(u'Deleting doc {} => {}'.format(doc.id, doc.to_dict()))\n",
    "#         doc.reference.delete()\n",
    "#         deleted = deleted + 1\n",
    "\n",
    "#     if deleted >= batch_size:\n",
    "#         return delete_collection(coll_ref, batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "delete_collection(fb_store.collection('dev_Session'), 20)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lwll_api",
   "language": "python",
   "name": "lwll_api"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
